
<details> <summary>Phase 1</summary>

- [X]  Linear Regression Model
    - [x]  Implement
    - [X]  Write DocStrings
- [X]  Logistic Regression Model
    - [X]  Implement
    - [X]  Write DocStrings
- [X]  Vanilla Neural Networks
    - [X]  Implement
    - [X]  Write DocStrings
</details>

<details> <summary> Phase 2</summary>


## 1. Validate Pre-built Models
- [X] Linear Regression
  - [X] Validate that it has similar accuracy to sklearn
  - [X] Ensure that it is robust to different datasets
  - [X] Update Examples
  - [ ] Add fucnctionality to save params
- [X] Logistic Regression
  - [x] Validate that it has similar accuracy to sklearn (not sure if possible)
  - [x] Ensure that it is robust to different datasets
  - [x] Update Examples
  - [ ] Add functionality to save params
- [X] Neural Network
  - [ ] Update Examples

## 2. Add Functionality for Custom Models
### 2.1 Initialization
- [ ] Add functionality for Xavier / He Initialization

### 2.2 Layers
- [ ] Add functionality for regular feed-forward layers
- [ ] Add functionality for Dropout layers
- [ ] Add functionality for BatchNorm layers

### 2.3 Regularization
- [ ] Add functionality for L1 Regularization
- [ ] Add functionality for L2 Regularization

### 2.4 Activation Functions
- [ ] Add functionality for different Activation Functions

### 2.5 Loss Functions & Metrics
- [ ] Add functionality for MSE
- [ ] Add functionality for MAE
- [ ] Add functionality for BCE
- [ ] Add functionality for CCE
- [ ] Add functionality for Smoothed CE
- [ ] Add functionality for Sparse CE (optional)

### 2.6 Optimizers
- [ ] Add functionality for Gradient Descent
- [ ] Add functionality for Momentum
- [ ] Add functionality for Nesterov Momentum
- [ ] Add functionality for RMSprop
- [ ] Add functionality for Adam
- [ ] Add functionality for AdaMax
- [ ] Add functionality for Nadam
- [ ] Add functionality for NadaMax

### 2.7 Learning Rate Scheduling
- [ ] Add functionality for Exponential Decay
- [ ] Add functionality for Halving
- [ ] Add functionality for Cyclical Learning Rate

## 3. Add Utilities
- [ ] Add MinMax Normalization
- [ ] Add Standardization (z-score)
- [ ] Add One-hot Encoding
- [ ] Add Mini-batching Data
- [ ] Saving Model Params
- [ ] Loading Bar While model is training ( like pytorch )
- [X] IO - CSV to Numpy
- [X] train_test_split
- [X] x_y_split


****
</details>